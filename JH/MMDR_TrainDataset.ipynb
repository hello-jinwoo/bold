{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import random as rd\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장혁이형 테스트할 때 순서대로 쭉 실행해보세요오~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TrainDataset\n",
    "\n",
    "- msmarco-docs.tsv 데이터는 크기가 너무 크고, train, test에 모두 쓰이므로 \n",
    "  각 클래스 변수로 두지 않고 global로 두는 게 나을 듯 ?\n",
    "\n",
    "    __init__(self, root)\n",
    "        - self.qid_to_query (dict) : qeury 정보, qid를 key로, qeury를 value로 가짐\n",
    "        - self.rel_qid_to_docid (dict) : qrels 정보, qid를 key로 해당 q에 대해 관련 docid를 value로 가짐\n",
    "        - self.top100 (pd.DataFrame) : bing에 의해 뽑힌 query 관련 100개 문서 \n",
    "        \n",
    "    __len__(self)\n",
    "        - qrels(rel_qid_to_docid) 길이 * 3 \n",
    "        - 1개의 query 당 qrels에서 1개, qrels 아닌 곳(일단은 top100)에서 2개\n",
    "        \n",
    "    __getitem__(self, index)\n",
    "        - q 길이 제한 20 token\n",
    "        - d 길이 제한 489 token (512 - 3 - 20)\n",
    "        - tokenizing 전에 너무 긴 (token 제한 * 10 보다 긴) 것들 사전 truncate\n",
    "        - index를 3으로 나눈 나머지 0 => 연관 있는 문서 from qrels\n",
    "        - index를 3으로 나눈 나머지 1,2 => 연관 없는 문서 from top100\n",
    "        - output: q_token_id(int list), d_token_id(int list), rel(int 0 or 1)\n",
    "        \n",
    "\"\"\"\n",
    "class TrainDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root=''):\n",
    "        queries = pd.read_csv(os.path.join(root, 'msmarco-doctrain-queries.tsv'), sep='\\t', header=None)\n",
    "        queries.columns = ['qid', 'query']\n",
    "        self.qid_to_query = dict(zip(queries['qid'], queries['query']))\n",
    "        \n",
    "        qrels = pd.read_csv(os.path.join(root, 'msmarco-doctrain-qrels.tsv'), sep=' ', header=None)\n",
    "        qrels.columns = ['qid', '0', 'docid', '1']\n",
    "        tmp_qid_list = list(qrels['qid'])\n",
    "        self.qid_list = []\n",
    "        for qid in tmp_qid_list:\n",
    "            self.qid_list.extend([qid, qid, qid])\n",
    "        self.rel_qid_to_docid = dict(zip(qrels['qid'], qrels['docid']))\n",
    "        \n",
    "        # msmarco-doctrain-top100 읽는 데 너무 오래 걸리면 global로 쓰자\n",
    "        self.top100 = pd.read_csv('msmarco-doctrain-top100', sep=' ', header=None)\n",
    "        self.top100.columns = ['qid', 'Q0', 'docid', 'rank', '-1', '-1']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qid_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        qid = self.qid_list[index]\n",
    "        rel_docid = rel_qid_to_docid[qid]\n",
    "\n",
    "        # 2/3 는 qrels에 없는(y == 0) 데이터\n",
    "        if index % 3:\n",
    "            y = 0\n",
    "            docid_list = list(self.top100[self.top100['qid'] == qid]['docid'])\n",
    "            docid_list.remove(rel_docid)\n",
    "            docid = rd.choice(docid_list)\n",
    "        # 1/3 는 qrels에 있는(y == 0) 데이터 \n",
    "        else:\n",
    "            y = 1\n",
    "            docid = rel_docid\n",
    "            \n",
    "        # Tokenizing query and doc\n",
    "        q = self.qid_to_query[qid]\n",
    "        d = docid_to_doc[docid]\n",
    "        \n",
    "        # q, d 길이 제한 선행 처리 (너무 긴 경우)\n",
    "        # (평균 token_len : text_len = 0.22 : 1)\n",
    "        \n",
    "        # q text len이 20(q 토큰 제한) * 10보다 큰 경우 truncate\n",
    "        if len(q) > 200:\n",
    "            q = q[:200]\n",
    "        # d text len이 500(q 토큰 제한) * 10보다 큰 경우 truncate\n",
    "        if len(d) > 5000:\n",
    "            d = d[:5000]\n",
    "        \n",
    "        # tokenize\n",
    "        q_token = tokenizer.tokenize(q)\n",
    "        q_token_len = len(q_token)\n",
    "        if q_token_len > 20:\n",
    "            q_token_len = 20\n",
    "            q_token = q_token[:q_token_len]\n",
    "        else:\n",
    "            q_token.extend(['[PAD]'] * (20 - q_token_len))\n",
    "        q_token_id = tokenizer.convert_tokens_to_ids(q_token)\n",
    "        \n",
    "        d_token = tokenizer.tokenize(d)\n",
    "        d_token_len = len(d_token)\n",
    "        if q_token_len > 489: # 512 - 3 ([CLS], [SEP], [SEP])\n",
    "            d_token_len = 489\n",
    "            d_token = d_token[:d_token_len]\n",
    "        else:\n",
    "            q_token.extend(['[PAD]'] * (489 - d_token_len))\n",
    "        d_token_id = tokenizer.convert_tokens_to_ids(d_token)\n",
    "        \n",
    "        assert len(q_token_id) == 20\n",
    "        assert len(d_token_id) == 489\n",
    "        \n",
    "        return q_token_id, d_token_id, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {file_path} 이 부분에 파일 위치 적기\n",
    "docs = pd.read_csv(os.path.join({file_path} + 'msmarco-docs.tsv'), sep='\\t', header=None)\n",
    "docs.columns = ['docid', 'url', 'title', 'body']\n",
    "docid_to_doc = dict(zip(docs['docid'], docs['body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}\n",
    "\n",
    "train_dataset = TrainDataset('')\n",
    "train_generator = data.DataLoader(train_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation 잘 되는지 확인\n",
    "# 첫번째 배치의 query, doc, labels shape과 내용 출력\n",
    "# 그 다음부터는 처음 배치랑 shape 다르면 출력\n",
    "\n",
    "first = True\n",
    "\n",
    "for local_q, local_d local_labels in train_generator:\n",
    "    if first:\n",
    "        local_q_shape = local_q.shape\n",
    "        local_d_shape = local_d.shape\n",
    "        local_labels_shape = local_labels.shape\n",
    "        print(local_q_shape, local_d_shape, local_labels_shape)\n",
    "        print(local_q, local_d, local_labels)\n",
    "        print()\n",
    "        first = False\n",
    "        \n",
    "    else:\n",
    "        if local_q.shape != local_q_shape:\n",
    "            print('Batch Q Different !!')\n",
    "            print(local_q.shape)\n",
    "            print()\n",
    "        if local_d.shape != local_d_shape:\n",
    "            print('Batch D Different !!')\n",
    "            print(local_d.shape)\n",
    "            print()\n",
    "        if local_labels.shape != local_labels_shape:\n",
    "            print('Labels Shape Different !!')\n",
    "            print(local_labels.shape)\n",
    "            print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a190d0f6b7423b91e421a4882f4eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=367013), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # make docid_to_doc\n",
    "# docs_lookup = pd.read_csv(\"msmarco-docs-lookup.tsv\", sep='\\t', header=None)\n",
    "# docs_lookup.columns = ['docid', -1, -1]\n",
    "# dicid_list = list(docs_lookup['docid'])\n",
    "\n",
    "# docid_to_doc = dict()\n",
    "# for docid in tqdm_notebook(docid_list):\n",
    "#     doc = 'hello ' * rd.randint(100, 6000)\n",
    "#     docid_to_doc[docid] = doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
